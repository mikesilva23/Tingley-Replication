---
title: "Rough Draft"
author: "Mike Silva"
date: "4/14/2020"
output: pdf_document
bibliography: 1006replicationbib.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)
```

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(foreign)
library(rstanarm)
library(stargazer)
library(generics)
library(tidybayes)
library(broom)
library(modelr)

theme_set(theme_tidybayes())
```

In this paper, Tingley et al. study how olfactory senses connect to assortive mating by ideology in humans. This explains how liberals tend to mate with other liberals, and conservatives tend to mate with other conservatives. The science behind olfactory sensibility in mates is exhibited best in animals, specifically mammals. As the paper explains, smell can signal mate immunocompetence, social compatibility, and other characteristics associated with mate quality and optimal reproduction. Tingley et al. perform a study where they surveyed 146 people on questions regarding the attractiveness of unknown liberals and conservatives. The models created from the survey outlined the affect that ideology and gender had on predicting someone's attractiveness after smelling their odor. They find that there is a positive coefficient for the targets and evaluators having matching ideologies, and a negative coefficient when the ideologies do not align. The coefficients explain the increase or decrease in attractiveness of the subjects. This further leads to a conclusion that olfactory attractiveness is just one of the many ways to explain attraction in mates. Studies have illustrated that characteristics like waist to hip ratio on women and the ability to provide resources in men, along with several other characteristics can also explain attraction in mates. Tingley et al further explain that olfactory attraction is something that is subconscious. Humans don't necessarily set out to smell each other in order to decide whether they're attracted to one another. Rather, our olfactory senses, connected with the parts of our brain that generate emotions, subconsciously tell us that we are interested in someone, and we tend to make those positive connections with members of the same ideology. The data and code used in this analysis replication is available on my github. ^[@github]


```{r, warning=FALSE, message=FALSE}
x <- read.dta("AJPSReplication.dta") %>%
  filter(!is.na(attractive)) %>%
  mutate(
    IdeoTargetBinary = ifelse(IdeoTarget >= 4, 1, 0),
    IdeoEvalBinary = ifelse(politicalIdeo >= 4, 1, 0),
    mn_attractive_eval = mean(attractive),
    same_ideology = IdeoTargetBinary == IdeoEvalBinary,
    same_gender = Male == MaleTarget,

    # They appeared to use actual ideology scale instead of binary

    ideodiffabs = abs(politicalIdeo - IdeoTarget)
  )

x <-
  x %>%
  group_by(ideval_n) %>%
  mutate(mn_attractive_eval2 = mean(attractive))
``` 

```{r}
graphic <-
  x %>%
  sample_n(21, replace = TRUE) %>%
  ggplot(aes(MaleTarget)) + geom_histogram(stat = "count") +
  scale_y_continuous(breaks = c(5, 10)) +
  labs(title = "Target Sex", x = "", y = "Frequency", caption = "This graph illustrates the targeted sexes of the participants. This is taken from a random sample of 21 participants.")

graphic
```



## Appendix

```{r, results='asis'}
model1 <-
  lm(attractive ~ same_ideology + same_gender + IdeoEvalBinary + IdeoTargetBinary + Male + MaleTarget +  mn_attractive + mn_attractive_eval2, data = x)


model2<-
  lm(attractive ~ ideodiffabs + same_gender + politicalIdeo + IdeoTarget + Male + MaleTarget  + mn_attractive + mn_attractive_eval2, data = x)

model3 <-
  lm(attractive ~ ideodiffabs + same_gender, data = x)

labs <- c("Same Ideology", "- Abs Ideology Diff.", "Same Sex", "Conservative Eval.", "Conservative Target","Ideology of Eval.", "Ideology of Target","Male Evaluator","Male Target","Avg. Target Attract","Avg. Eval. Attract")

#cluster_se <- function(model, cluster){
#  if(nrow(model.matrix(model))!=length(cluster)){
#   stop("check your data: cluster variable has different N than model")}
#  M <- length(unique(cluster))
#  N <- length(cluster)          
#  K <- model$rank  
#  dfc <- (M/(M - 1)) * ((N - 1)/(N - K))
#  uj  <- apply(estfun(model), 2, function(x) tapply(x, cluster, sum));
#  rcse.cov <- dfc * sandwich(model, meat = crossprod(uj)/N)
#  return(coeftest(model, vcov. = rcse.cov))
#}

#cluster_se(model1, x$ideval_n)

stargazer(model1, model2, model3, header = FALSE, style = "ajps", type = "latex", omit.stat = c("rsq", "adj.rsq", "ser", "f"), title = "Odor Attraction as a Function of Ideological Similarity", intercept.bottom = T, dep.var.labels.include = F, digits = 4, covariate.labels = labs, dep.var.caption = "")


```




## Extension

Pictured below is a graph of predicted outcomes from a posterior distribution of one model created by Tingley et al combined with the actual outcome data from the model. 

```{r Extension}
stan_fit <-
  stan_lm(attractive ~ same_ideology + same_gender + IdeoEvalBinary + IdeoTargetBinary + Male + MaleTarget +  mn_attractive + mn_attractive_eval2, data = x, prior = NULL)

predict_graphic <- 
  pp_check(stan_fit, "dens_overlay", seed = 02364) +
  labs(x = "Attractive") + 
  scale_x_continuous()
predict_graphic
```

Through this graph, we can see how well the data explains the outcome we are looking at in our model, which is the measure of attractiveness of the subjects. The dark blue line illustrates the actual outcomes of the model. As you can see, there is a lot of fluctuation between each value. This is because the observers only graded on a whole number scale. The peaks in each hump represent each value- there are 7 peaks that coordinate to each of the 'attractive' values. The faded blue line refers to the posterior iterations ran using pp_check that predicts outcomes using the information in our model. 

Through this graph we can confidently say that our model significantly explains the data. In most cases the predicted values align closesly with the outcome variables, emphasizing how the model is representative of the data. In a the cases of attractive values 1, 4, and 5, the predicted values underestimated compared to the actual values. This may be because there is less data for those values, so the prediction is less accurate. Regardless, this graph confirms the accuracy and significance of the model created by Tingley et al. 




## Selected Bibliography + References:


@AlfordJohn

@Bereczkei

@BlausteinAndrew

@ByrneD

@paper1

